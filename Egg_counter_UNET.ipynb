{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Egg_counter_UNET",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeynepRuveyda/Egg_Counter/blob/main/Egg_counter_UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdrlg4laVL88"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet101 import ResNet101\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from google.colab import files \n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlxYNRkvVtoA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2lViTE1EgeO"
      },
      "source": [
        "# ResUnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syZIVCibFWgM"
      },
      "source": [
        "%cd /content/drive/My Drive/eggs_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6ERuIFRq3p"
      },
      "source": [
        "\n",
        "image_path = []\n",
        "mask_path = []\n",
        "for i in range(1,12):\n",
        "  image_path.append(str(i)+\"_1.png\")\n",
        "  mask_path.append(str(i)+\"_1_mask.png\")\n",
        "  image_path.append(str(i)+\"_2.png\")\n",
        "  mask_path.append(str(i)+\"_2_mask.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsquDzkFEROE"
      },
      "source": [
        "df = {\"image_path\":image_path,\"mask_path\":mask_path}\n",
        "df = pd.DataFrame(df)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS5DqOy66JCX"
      },
      "source": [
        "def check_size(img):\n",
        "  img = cv2.imread(img)\n",
        "  \n",
        "  return print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fLZiQ3vGKW"
      },
      "source": [
        "for i in mask_path:\n",
        "  check_size(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxYnCyeluZik"
      },
      "source": [
        "X_test = pd.DataFrame({\"id\":[\"1_test\"],\"image_path\":[\"1_test.png\"]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XA2FqbTN7If"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val = train_test_split(df, test_size=0.10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUJVNE0EN89I"
      },
      "source": [
        "train_ids = list(X_train.image_path)\n",
        "train_mask = list(X_train.mask_path)\n",
        "\n",
        "val_ids = list(X_val.image_path)\n",
        "val_mask= list(X_val.mask_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoSMOtjiN_WE"
      },
      "source": [
        "from utilities import DataGenerator\n",
        "\n",
        "training_generator = DataGenerator(train_ids,train_mask)\n",
        "validation_generator = DataGenerator(val_ids,val_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsfIEOcqOGWX"
      },
      "source": [
        "def resblock(X, f):\n",
        "  \n",
        "\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (1,1) ,strides = (1,1),kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "\n",
        "\n",
        "  X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n",
        "  X_copy = BatchNormalization()(X_copy)\n",
        "\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYi0-gFJOKnC"
      },
      "source": [
        "def upsample_concat(x, skip):\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  merge = Concatenate()([x, skip])\n",
        "\n",
        "  return merge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rogPsEPOVt1"
      },
      "source": [
        "input_shape = (1024,1024,3)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Stage 1\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "pool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n",
        "\n",
        "# Stage 2\n",
        "conv2_in = resblock(pool_1, 32)\n",
        "pool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n",
        "\n",
        "# Stage 3\n",
        "conv3_in = resblock(pool_2, 64)\n",
        "pool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n",
        "\n",
        "# Stage 4\n",
        "conv4_in = resblock(pool_3, 128)\n",
        "pool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n",
        "# Stage 5\n",
        "conv5_in = resblock(pool_4, 256)\n",
        "pool_5 = MaxPool2D(pool_size = (2,2))(conv5_in)\n",
        "# Stage 6\n",
        "conv6_in = resblock(pool_5, 512)\n",
        "pool_6 = MaxPool2D(pool_size = (2,2))(conv6_in)\n",
        "\n",
        "\n",
        "# Stage 7 (Bottle Neck)\n",
        "conv7_in = resblock(pool_6, 1024)\n",
        "\n",
        "# Upscale stage 1\n",
        "up_1 = upsample_concat(conv7_in, conv6_in)\n",
        "up_1 = resblock(up_1, 512)\n",
        "\n",
        "# Upscale stage 2\n",
        "up_2 = upsample_concat(up_1, conv5_in)\n",
        "up_2 = resblock(up_2, 256)\n",
        "\n",
        "# Upscale stage 3\n",
        "up_3 = upsample_concat(up_2, conv4_in)\n",
        "up_3 = resblock(up_3, 128)\n",
        "\n",
        "# Upscale stage 4\n",
        "up_4 = upsample_concat(up_3, conv3_in)\n",
        "up_4 = resblock(up_4, 64)\n",
        "\n",
        "# Upscale stage 5\n",
        "up_5 = upsample_concat(up_4, conv2_in)\n",
        "up_5 = resblock(up_5, 32)\n",
        "\n",
        "# Upscale stage 6\n",
        "up_6 = upsample_concat(up_5, conv1_in)\n",
        "up_6 = resblock(up_6, 16)\n",
        "\n",
        "\n",
        "# Final Output\n",
        "output = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(up_6)\n",
        "\n",
        "model_seg = Model(inputs = X_input, outputs = output )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n29o_EaaOZLV"
      },
      "source": [
        "model_seg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw-7LIa_OcIt"
      },
      "source": [
        "from utilities import focal_tversky, tversky_loss, tversky"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbVHo8KYOhen"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 4.0000e-05)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULnxTCV5P2uK"
      },
      "source": [
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "checkpointer = ModelCheckpoint(filepath=\"seg-weights.hdf5\", verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDJkHcIUP6vb"
      },
      "source": [
        "seg = model_seg.fit(training_generator, epochs = 300, validation_data = validation_generator, callbacks = [checkpointer, earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVLRNS7RWdjb"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(seg.history['loss']);\n",
        "plt.plot(seg.history['val_loss']);\n",
        "plt.title(\"SEG Model focal tversky Loss\");\n",
        "plt.ylabel(\"focal tversky loss\");\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.legend(['train', 'val']);\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(seg.history['tversky']);\n",
        "plt.plot(seg.history['val_tversky']);\n",
        "plt.title(\"SEG Model tversky score\");\n",
        "plt.ylabel(\"tversky Accuracy\");\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.legend(['train', 'val']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HKb_YqCQAO6"
      },
      "source": [
        "model_json = model_seg.to_json()\n",
        "with open(\"seg-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX-w8KP5VXuD"
      },
      "source": [
        "from utilities import focal_tversky, tversky_loss, tversky\n",
        "\n",
        "with open('seg-model.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "\n",
        "model_seg = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_seg.load_weights('seg-weights.hdf5')\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkOU_NrVkFN"
      },
      "source": [
        "from utilities import prediction\n",
        "\n",
        "image_id, mask= prediction(X_test, model_seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y48epIeWVqKk"
      },
      "source": [
        "df_pred = pd.DataFrame({'image_path': image_id,'predicted_mask': mask})\n",
        "df_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUZPRduzVrbm"
      },
      "source": [
        "df_pred = X_test.merge(df_pred, on = 'image_path')\n",
        "df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt81yY1nVwzw"
      },
      "source": [
        "fig, axs = plt.subplots(2, figsize=(30, 50))\n",
        "for i in range(len(df_pred)):\n",
        "\n",
        "  # read the images and convert them to RGB format\n",
        "  img = io.imread(df_pred.image_path[i])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  axs[0].title.set_text(\"eggs\")\n",
        "  axs[0].imshow(img)\n",
        "\n",
        " \n",
        "\n",
        "  # Obtain the predicted mask for the image \n",
        "  predicted_mask = np.asarray(df_pred.predicted_mask[i])[0].squeeze().round()\n",
        "  axs[1].title.set_text(\"AI Predicted Mask\")\n",
        "  axs[1].imshow(predicted_mask)\n",
        "    \n",
        "\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LdJSZi7tbNu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}